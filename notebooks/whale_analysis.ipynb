{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  A Whale off the Port(folio)\n",
    " ---\n",
    "\n",
    " In this assignment, you'll get to use what you've learned this week to evaluate the performance among various algorithmic, hedge, and mutual fund portfolios and compare them against the S&P 500 Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "# Import of dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps. After cleaning, combine all DataFrames into a single DataFrame.\n",
    "\n",
    "Files:\n",
    "\n",
    "* `whale_returns.csv`: Contains returns of some famous \"whale\" investors' portfolios.\n",
    "\n",
    "* `algo_returns.csv`: Contains returns from the in-house trading algorithms from Harold's company.\n",
    "\n",
    "* `sp500_history.csv`: Contains historical closing prices of the S&P 500 Index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale Returns\n",
    "\n",
    "Read the Whale Portfolio daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading whale returns\n",
    "# Defining the file path\n",
    "whale_returns_path = Path(\"../data/whale_returns.csv\")\n",
    "\n",
    "# Reading the CSV file into a DataFrame\n",
    "whale_returns_df = pd.read_csv(whale_returns_path, index_col=\"Date\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "# Displaying the first few rows of the DataFrame to verify output\n",
    "whale_returns_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "# Counting available nulls\n",
    "null_counts = whale_returns_df.isnull().sum()\n",
    "\n",
    "# Printing results\n",
    "print(\"Null Counts:\")\n",
    "print(null_counts)\n",
    "\n",
    "# Ploting null counts\n",
    "plt.figure(figsize=(7, 4))\n",
    "null_counts.plot(kind='bar')\n",
    "plt.title('Null Counts in Whale Returns Data')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Null Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# Dropping nulls\n",
    "whale_returns_df.dropna(inplace=True)\n",
    "\n",
    "# Printing results\n",
    "print(\"Null Counts after dropping nulls:\")\n",
    "print(whale_returns_df.isnull().sum())\n",
    "\n",
    "# Ploting null counts\n",
    "plt.figure(figsize=(7, 4))\n",
    "whale_returns_df.isnull().sum().plot(kind='bar', color='skyblue')\n",
    "plt.title('Null Counts After Dropping Nulls')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Null Counts')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Daily Returns\n",
    "\n",
    "Read the algorithmic daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading algorithmic returns\n",
    "# Reading the CSV file into a DataFrame\n",
    "algo_returns_df = pd.read_csv(\"../data/algo_returns.csv\", index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "# Displaying the first 5 rows of the DataFrame\n",
    "print(algo_returns_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "# Counting nulls\n",
    "null_counts_algo = algo_returns_df.isnull().sum()\n",
    "\n",
    "# Printing results\n",
    "print(\"Null Counts - Algorithmic Returns:\")\n",
    "print(null_counts_algo)\n",
    "\n",
    "# Visualizing null counts\n",
    "plt.figure(figsize=(7, 4))\n",
    "null_counts_algo.plot(kind='bar', color='skyblue')\n",
    "plt.title('Null Counts - Algorithmic Returns')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# Droping nulls\n",
    "algo_returns_df.dropna(inplace=True)\n",
    "\n",
    "# Printing results\n",
    "print(\"Null Counts - Algorithmic Returns after dropping nulls:\")\n",
    "print(algo_returns_df.isnull().sum())\n",
    "\n",
    "# Visualizing null counts after dropping\n",
    "plt.figure(figsize=(7, 4))\n",
    "algo_returns_df.isnull().sum().plot(kind='bar')\n",
    "plt.title(\"Null Counts - Algorithmic Returns after Dropping Nulls\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Null Counts\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 Returns\n",
    "\n",
    "Read the S&P 500 historic closing prices and create a new daily returns DataFrame from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading S&P 500 Closing Prices\n",
    "# Defining the file path\n",
    "sp500_csv_path = Path(\"../data/sp500_history.csv\")\n",
    "\n",
    "# Reading the CSV file into a DataFrame\n",
    "sp500_df = pd.read_csv(sp500_csv_path, index_col=\"Date\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "# Displaying the first few rows of the DataFrame\n",
    "print(sp500_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data Types\n",
    "# Checking the data types of the S&P 500 DataFrame\n",
    "sp500_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Data Types\n",
    "# Removing the dollar signs and commas in the Close column\n",
    "sp500_df['Close'] = sp500_df['Close'].str.replace('$', '').str.replace(',', '')\n",
    "\n",
    "# Converting the Close column to a float\n",
    "sp500_df['Close'] = sp500_df['Close'].astype(float)\n",
    "\n",
    "# Confirming the data types have been fixed\n",
    "print(\"Data Types:\")\n",
    "print(sp500_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns\n",
    "# Calculating daily returns\n",
    "sp500_daily_returns = sp500_df['Close'].pct_change()\n",
    "\n",
    "# Droping the first row since it will be NaN after calculating returns\n",
    "sp500_daily_returns = sp500_daily_returns.dropna()\n",
    "\n",
    "# Displaying the first few rows of the resulting DataFrame\n",
    "sp500_daily_returns.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# Droping nulls\n",
    "sp500_daily_returns.dropna(inplace=True)\n",
    "\n",
    "# Displaying the first few rows of the DataFrame\n",
    "sp500_daily_returns.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename `Close` Column to be specific to this portfolio.\n",
    "# Renaming the 'Close' column to 'SP500_Daily_Returns'\n",
    "sp500_df.rename(columns={'Close': 'SP500_Daily_Returns'}, inplace=True)\n",
    "\n",
    "# Displaying the DataFrame with both the dates and corresponding S&P 500 daily returns\n",
    "print(sp500_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Whale, Algorithmic, and S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Whale Returns, Algorithmic Returns, and the S&P 500 Returns into a single DataFrame with columns for each portfolio's returns.\n",
    "# Joining Whale Returns, Algorithmic Returns, and the S&P 500 Returns into a single DataFrame\n",
    "combined_returns_df = pd.concat([whale_returns_df, algo_returns_df, sp500_df], axis='columns', join='inner')\n",
    "\n",
    "# Displaying the first few rows of the combined DataFrame\n",
    "combined_returns_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Quantitative Analysis\n",
    "\n",
    "In this section, you will calculate and visualize performance and risk metrics for the portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Anlysis\n",
    "\n",
    "#### Calculate and Plot the daily returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading CSV files\n",
    "whale_returns_df = pd.read_csv('../data/whale_returns.csv', index_col='Date', parse_dates=True)\n",
    "algo_returns_df = pd.read_csv('../data/algo_returns.csv', index_col='Date', parse_dates=True)\n",
    "sp500_df = pd.read_csv('../data/sp500_history.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Data Cleaning and Preprocessing\n",
    "# Checking for missing values and handle if necessary\n",
    "\n",
    "# Combining DataFrames if needed\n",
    "\n",
    "# Printing basic information about the data\n",
    "print(\"Whale Returns Data:\")\n",
    "print(whale_returns_df.info())\n",
    "\n",
    "print(\"\\nAlgorithmic Returns Data:\")\n",
    "print(algo_returns_df.info())\n",
    "\n",
    "print(\"\\nS&P 500 Data:\")\n",
    "print(sp500_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readin the data from CSV files\n",
    "whale_returns_df = pd.read_csv('../data/whale_returns.csv', index_col='Date', parse_dates=True)\n",
    "algo_returns_df = pd.read_csv('../data/algo_returns.csv', index_col='Date', parse_dates=True)\n",
    "sp500_df = pd.read_csv('../data/sp500_history.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Printing data info to check if everything is correct\n",
    "print(\"Whale Returns Data:\")\n",
    "print(whale_returns_df.info())\n",
    "print(\"\\nAlgorithmic Returns Data:\")\n",
    "print(algo_returns_df.info())\n",
    "print(\"\\nS&P 500 Data:\")\n",
    "print(sp500_df.info())\n",
    "\n",
    "# Handling missing values\n",
    "whale_returns_df.dropna(inplace=True)\n",
    "algo_returns_df.dropna(inplace=True)\n",
    "sp500_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily returns of all portfolios\n",
    "# Defining a function to plot daily returns for each portfolio\n",
    "def plot_portfolio_returns(df, portfolio_name):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(df.index, df[portfolio_name], label=portfolio_name)\n",
    "    plt.title(f\"Daily Returns of {portfolio_name}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Daily Returns\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Ploting daily returns for each portfolio\n",
    "for portfolio in selected_columns:\n",
    "    plot_portfolio_returns(combined_returns_df, portfolio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate and Plot cumulative returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative returns of all portfolios\n",
    "# Calculating cumulative returns of all portfolios\n",
    "cumulative_returns_df = (1 + combined_returns_df).cumprod() - 1\n",
    "\n",
    "# Plot cumulative returns\n",
    "# Ploting cumulative returns\n",
    "plt.figure(figsize=(14, 7))\n",
    "for column in cumulative_returns_df.columns:\n",
    "    plt.plot(cumulative_returns_df.index, cumulative_returns_df[column], label=column)\n",
    "\n",
    "plt.title(\"Cumulative Returns of Portfolios\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Returns\")\n",
    "\n",
    "# Adjusting x-axis ticks\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(10))  # Adjusting the number of ticks\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Analysis\n",
    "\n",
    "Determine the _risk_ of each portfolio:\n",
    "\n",
    "1. Create a box plot for each portfolio. \n",
    "2. Calculate the standard deviation for all portfolios\n",
    "4. Determine which portfolios are riskier than the S&P 500\n",
    "5. Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a box plot for each portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot to visually show risk\n",
    "# Creating box plot to visually show risk\n",
    "plt.figure(figsize=(14, 7))\n",
    "combined_returns_df.plot(kind='box', figsize=(14,7))\n",
    "plt.title(\"Box Plot of Daily Returns for Portfolios\")\n",
    "plt.ylabel(\"Daily Returns\")\n",
    "\n",
    "# Adjusting x-axis labels\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily standard deviations of all portfolios\n",
    "# Calculating and printing the daily standard deviations of all portfolios\n",
    "daily_std_dev = combined_returns_df.std()\n",
    "print(\"Daily Standard Deviations of Portfolios:\")\n",
    "print(daily_std_dev)\n",
    "\n",
    "# Box plotting to visually show risk\n",
    "plt.figure(figsize=(14, 7))\n",
    "daily_std_dev.plot(kind='bar', color='skyblue', alpha=0.75)\n",
    "plt.title('Daily Standard Deviations of Portfolios')\n",
    "plt.xlabel('Portfolios')\n",
    "plt.ylabel('Standard Deviation')\n",
    "\n",
    "# Adjust x-axis labels\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which portfolios are riskier than the S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate  the daily standard deviation of S&P 500\n",
    "# Calculating the daily standard deviation of S&P 500\n",
    "sp500_daily_std = combined_returns_df['SP500_Daily_Returns'].std()\n",
    "\n",
    "# Determine which portfolios are riskier than the S&P 500\n",
    "# Determining which portfolios are riskier than the S&P 500\n",
    "riskier_portfolios = daily_std_dev[daily_std_dev > sp500_daily_std]\n",
    "print(\"Portfolios with Standard Deviation Higher than S&P 500:\")\n",
    "print(riskier_portfolios)\n",
    "\n",
    "# Visualizing the comparison\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(daily_std_dev.index, daily_std_dev, color='skyblue', alpha=0.75, label='Portfolio Standard Deviation')\n",
    "plt.axhline(y=sp500_daily_std, color='red', linestyle='--', label='S&P 500 Standard Deviation')\n",
    "plt.title('Daily Standard Deviations of Portfolios')\n",
    "plt.xlabel('Portfolios')\n",
    "plt.ylabel('Standard Deviation')\n",
    "\n",
    "# Adjusting x-axis labels\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "# Calculating the annualized standard deviation (252 trading days)\n",
    "annualized_std_dev = daily_std_dev * np.sqrt(252)\n",
    "print(\"Annualized Standard Deviations of Portfolios:\")\n",
    "print(annualized_std_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics\n",
    "\n",
    "Risk changes over time. Analyze the rolling statistics for Risk and Beta. \n",
    "\n",
    "1. Calculate and plot the rolling standard deviation for all portfolios using a 21-day window\n",
    "2. Calculate the correlation between each stock to determine which portfolios may mimick the S&P 500\n",
    "3. Choose one portfolio, then calculate and plot the 60-day rolling beta between it and the S&P 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot rolling `std` for all portfolios with 21-day window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rolling standard deviation for all portfolios using a 21-day window\n",
    "# Calculating the rolling standard deviation for all portfolios with a 21-day window\n",
    "rolling_std = combined_returns_df.rolling(window=21).std()\n",
    "\n",
    "# Plot the rolling standard deviation\n",
    "# Ploting the rolling standard deviation\n",
    "plt.figure(figsize=(14, 7))\n",
    "for column in combined_returns_df.columns:\n",
    "    plt.plot(rolling_std.index, rolling_std[column], label=column)\n",
    "\n",
    "plt.title(\"Rolling 21-Day Standard Deviation of Portfolios\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Rolling Standard Deviation\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn library\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation\n",
    "# Calculating the correlation matrix\n",
    "correlation_matrix = combined_returns_df.corr()\n",
    "\n",
    "# Display de correlation matrix\n",
    "# Displaying the correlation matrix\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Portfolios\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Plot Beta for a chosen portfolio and the S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance of a single portfolio\n",
    "# Calculating covariance of a single portfolio with S&P 500\n",
    "covariance = combined_returns_df['SOROS FUND MANAGEMENT LLC'].cov(combined_returns_df['SP500_Daily_Returns'])\n",
    "\n",
    "# Calculate variance of S&P 500\n",
    "# Calculating variance of S&P 500\n",
    "sp500_variance = combined_returns_df['SP500_Daily_Returns'].var()\n",
    "\n",
    "# Compute beta\n",
    "# Computing beta\n",
    "beta = covariance / sp500_variance\n",
    "\n",
    "# Plot beta trend\n",
    "# Plotting beta trend\n",
    "rolling_covariance = combined_returns_df['SOROS FUND MANAGEMENT LLC'].rolling(window=60).cov(combined_returns_df['SP500_Daily_Returns'])\n",
    "rolling_variance = combined_returns_df['SP500_Daily_Returns'].rolling(window=60).var()\n",
    "rolling_beta = rolling_covariance / rolling_variance\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(rolling_beta.index, rolling_beta, label='Rolling 60-Day Beta')\n",
    "plt.title(\"Rolling 60-Day Beta of SOROS FUND MANAGEMENT LLC\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Beta\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics Challenge: Exponentially Weighted Average \n",
    "\n",
    "An alternative way to calculate a rolling window is to take the exponentially weighted moving average. This is like a moving window average, but it assigns greater importance to more recent observations. Try calculating the [`ewm`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html) with a 21-day half life for each portfolio, using standard deviation (`std`) as the metric of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `ewm` to calculate the rolling window\n",
    "# Calculating exponentially weighted moving average (EWMA) with a 21-day half-life for each portfolio\n",
    "ewma_std = combined_returns_df.ewm(halflife=21).std()\n",
    "\n",
    "# Plotting EWMA for each portfolio\n",
    "plt.figure(figsize=(14, 7))\n",
    "for column in combined_returns_df.columns:\n",
    "    plt.plot(ewma_std.index, ewma_std[column], label=column)\n",
    "\n",
    "plt.title(\"Exponentially Weighted Moving Average (EWMA) with 21-Day Half-Life\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"EWMA Standard Deviation\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpe Ratios\n",
    "In reality, investment managers and thier institutional investors look at the ratio of return-to-risk, and not just returns alone. After all, if you could invest in one of two portfolios, and each offered the same 10% return, yet one offered lower risk, you'd take that one, right?\n",
    "\n",
    "### Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualized Sharpe Ratios\n",
    "# Calculating Sharpe ratios\n",
    "sharpe_ratios = (combined_returns_df.mean() * 252) / (combined_returns_df.std() * np.sqrt(252))\n",
    "\n",
    "# Printing Sharpe ratios\n",
    "print(\"Sharpe Ratios:\")\n",
    "print(sharpe_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "# Visualizing Sharpe ratios\n",
    "plt.figure(figsize=(14, 7))\n",
    "sharpe_ratios.plot(kind='bar', color='skyblue')\n",
    "plt.title('Sharpe Ratios of Portfolios')\n",
    "plt.xlabel('Portfolios')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine whether the algorithmic strategies outperform both the market (S&P 500) and the whales portfolios.\n",
    "\n",
    "Write your answer here!\n",
    "\n",
    "Based on the Sharpe ratios calculated:\n",
    "\n",
    "- Algo 1 has a Sharpe ratio of 1.378648.\n",
    "- Algo 2 has a Sharpe ratio of 0.501364.\n",
    "- S&P 500 has a Sharpe ratio of 123.476112.\n",
    "\n",
    "Comparing these ratios:\n",
    "- Algo 1 has a higher Sharpe ratio than both Algo 2 and the S&P 500, indicating superior risk-adjusted returns.\n",
    "- Algo 2 also outperforms the S&P 500 in terms of risk-adjusted returns, but to a lesser extent compared to Algo 1.\n",
    "- The Sharpe ratio of the S&P 500 is extremely high, likely indicating an issue with the calculation.\n",
    "\n",
    "In conclusion, both algorithmic strategies (Algo 1 and Algo 2) appear to outperform both the market (S&P 500) and the whale portfolios in terms of risk-adjusted returns. However, further investigation may be needed to verify the accuracy of the S&P 500 Sharpe ratio, as it seems unusually high.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Custom Portfolio\n",
    "\n",
    "In this section, you will build your own portfolio of stocks, calculate the returns, and compare the results to the Whale Portfolios and the S&P 500. \n",
    "\n",
    "1. Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock.\n",
    "2. Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock\n",
    "3. Join your portfolio returns to the DataFrame that contains all of the portfolio returns\n",
    "4. Re-run the performance and risk analysis with your portfolio to see how it compares to the others\n",
    "5. Include correlation analysis to determine which stocks (if any) are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Reading data from 1st stock\n",
    "# Reading data from the first stock (AAPL)\n",
    "aapl_data = pd.read_csv('../data/aapl_historical.csv')\n",
    "\n",
    "# Displaying the first few rows of the AAPL data\n",
    "print(\"AAPL Historical Data:\")\n",
    "print(aapl_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Reading data from 2nd stock\n",
    "# Reading data from the second stock (COST)\n",
    "cost_df = pd.read_csv('../data/cost_historical.csv')\n",
    "\n",
    "# Displaying the first few rows of the COST data\n",
    "print(cost_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Reading data from 3rd stock\n",
    "# Reading data from the third stock (GOOG)\n",
    "cost_df = pd.read_csv('../data/goog_historical.csv')\n",
    "\n",
    "# Displaying the first few rows of the GOOG data\n",
    "print(cost_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all stocks in a single DataFrame\n",
    "# Reading data from the first stock (AAPL)\n",
    "aapl_historical_df = pd.read_csv(\"../data/aapl_historical.csv\")\n",
    "\n",
    "# Reading data from the second stock (COST)\n",
    "cost_historical_df = pd.read_csv(\"../data/cost_historical.csv\")\n",
    "\n",
    "# Reading data from the third stock (GOOG)\n",
    "goog_historical_df = pd.read_csv(\"../data/goog_historical.csv\")\n",
    "\n",
    "# Combining all stocks into a single DataFrame\n",
    "combined_df = pd.concat([aapl_historical_df[\"NOCP\"], cost_historical_df[\"NOCP\"], goog_historical_df[\"NOCP\"]], axis=\"columns\", join=\"inner\")\n",
    "\n",
    "# Renaming columns\n",
    "combined_df.columns = [\"AAPL\", \"COST\", \"GOOG\"]\n",
    "\n",
    "# Displaying the first few rows of the combined DataFrame\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Date index\n",
    "# Resetting Date index\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Displaying the first few rows to verify that the change happened\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize portfolio data by having a column per symbol\n",
    "# Reorganizing portfolio data by having a column per symbol\n",
    "reorganized_df = combined_df.copy()\n",
    "reorganized_df.columns = [\"AAPL\", \"COST\", \"GOOG\"]\n",
    "\n",
    "# Printing the reorganized DataFrame\n",
    "print(reorganized_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "# Calculating daily returns\n",
    "daily_returns = reorganized_df.pct_change()\n",
    "\n",
    "# Drop NAs\n",
    "# Droping NAs\n",
    "daily_returns.dropna(inplace=True)\n",
    "\n",
    "# Display sample data\n",
    "# Displaying sample data\n",
    "print(daily_returns.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights\n",
    "# Setting weights\n",
    "weights = [1/3, 1/3, 1/3]\n",
    "\n",
    "# Calculate portfolio return\n",
    "# Calculating portfolio return\n",
    "portfolio_return = daily_returns.dot(weights)\n",
    "\n",
    "# Display sample data\n",
    "# Displaying sample data\n",
    "print(portfolio_return.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join your portfolio returns to the DataFrame that contains all of the portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join your returns DataFrame to the original returns DataFrame\n",
    "# Joining the returns DataFrame to the original returns DataFrame\n",
    "combined_returns_df[\"Custom Portfolio\"] = portfolio_return\n",
    "\n",
    "# Displaying sample data\n",
    "print(combined_returns_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only compare dates where return data exists for all the stocks (drop NaNs)\n",
    "# Only comparing dates where return data exists for all the stocks (drop NaNs)\n",
    "combined_returns_df.dropna(inplace=True)\n",
    "\n",
    "# Displaying sample data\n",
    "print(combined_returns_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the risk analysis with your portfolio to see how it compares to the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized `std`\n",
    "# Calculating the annualized std\n",
    "annualized_std = combined_returns_df.std() * np.sqrt(252)\n",
    "\n",
    "# Displaying sample data\n",
    "print(annualized_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot rolling `std` with 21-day window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling standard deviation\n",
    "# Calculating rolling standard deviation\n",
    "rolling_std = combined_returns_df.rolling(window=21).std()\n",
    "\n",
    "# Plot rolling standard deviation\n",
    "# Plotting rolling standard deviation\n",
    "plt.figure(figsize=(14, 7))\n",
    "for column in combined_returns_df.columns:\n",
    "    plt.plot(rolling_std.index, rolling_std[column], label=column)\n",
    "\n",
    "plt.title(\"Rolling 21-Day Standard Deviation of Portfolios\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Rolling Standard Deviation\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the correlation\n",
    "# Calculating correlation\n",
    "correlation_matrix = combined_returns_df.corr()\n",
    "\n",
    "# Plotting correlation matrix\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Portfolios\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Plot Rolling 60-day Beta for Your Portfolio compared to the S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot Beta\n",
    "# Calculating covariance of each portfolio with S&P 500\n",
    "covariance = combined_returns_df.cov()\n",
    "\n",
    "# Calculating variance of S&P 500\n",
    "sp500_variance = combined_returns_df['SP500_Daily_Returns'].var()\n",
    "\n",
    "# Computing beta\n",
    "beta = covariance['SP500_Daily_Returns'] / sp500_variance\n",
    "\n",
    "# Plotting beta trend\n",
    "plt.figure(figsize=(14, 7))\n",
    "beta.plot(kind='bar', color='skyblue', alpha=0.75)\n",
    "plt.title('Beta Values of Portfolios')\n",
    "plt.xlabel('Portfolios')\n",
    "plt.ylabel('Beta')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Annualized Sharpe Ratios\n",
    "# Calculating Sharpe ratios\n",
    "sharpe_ratios = (combined_returns_df.mean() * 252) / (combined_returns_df.std() * np.sqrt(252))\n",
    "\n",
    "# Plotting Annualized Sharpe Ratios\n",
    "plt.figure(figsize=(14, 7))\n",
    "sharpe_ratios.plot(kind='bar', color='skyblue', alpha=0.75)\n",
    "plt.title('Annualized Sharpe Ratios of Portfolios')\n",
    "plt.xlabel('Portfolios')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "# Visualizing the Sharpe ratios as a bar plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(x=sharpe_ratios.index, y=sharpe_ratios.values, color='skyblue', alpha=0.75)\n",
    "plt.title('Sharpe Ratios of Portfolios')\n",
    "plt.xlabel('Portfolios')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does your portfolio do?\n",
    "\n",
    "Write your answer here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
